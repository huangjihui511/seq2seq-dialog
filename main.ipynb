{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitc618d87d24fd41819fe0e569b8dfcad8",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('Hello doctor, I get a cough for the last few days, which is heavy during night times .  No raise in temperature but feeling tired with no travel history .  No contact with any Covid-19 persons .  It has been four to five days and has drunk a lot of Benadryl and took Paracetamol too .  Doctors have shut the OP so do not know what to do? Please help . ',\n 'Hello, I understand your concern .  I just have a few more questions . Does your cough has phlegm? Any other symptoms like difficulty breathing? Any other medical condition such as asthma, hypertension? Are you a smoker? Alcoholic beverage drinker?')"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "path = \"COVID-Dialogue-Dataset-English.txt\"\n",
    "f = open(path,encoding=\"UTF-8\")\n",
    "l1 = f.read()\n",
    "l2 = l1.split(\"id=\")\n",
    "p2d = []\n",
    "d2p = []\n",
    "\n",
    "def clean_sentence(str):\n",
    "    str = str.replace(\".\", \" . \").replace(\"\\n\", \"\").replace(\"/\",\"\")\n",
    "    return str\n",
    "for item in l2:\n",
    "    if len(item) != 0:\n",
    "        temp = item.split(\"Dialogue\\nPatient:\")\n",
    "        if len(temp) > 1:\n",
    "            item2 = temp[1]\n",
    "            item3 = item2.split(\"Patient:\")\n",
    "            l = []\n",
    "            if len(item3) != 0:\n",
    "                for item4 in item3:\n",
    "                    item5 = item4.split(\"Doctor:\")\n",
    "                    item5 = [clean_sentence(item6) for item6 in item5]\n",
    "                    l += item5\n",
    "            for i in range(1, len(l), 2):\n",
    "                p2d.append((l[i - 1].strip(\"\\n\"), l[i].strip(\"\\n\")))\n",
    "                if i + 1 < len(l):\n",
    "                    d2p.append((l[i].strip(\"\\n\"), l[i + 1].strip(\"\\n\")))\n",
    "data = p2d + d2p\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_str = json.dumps(data)\n",
    "f = open(\"dia_data.txt\", \"w\")\n",
    "json.dump(json_str,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "352\n184\n647\n76\n301\n238\n773\n1496\n428\n1454\n3579\n1395\n245\n353\n1557\n158\n35\n24\n25\n19\n47\n37\n45\n26\n35\n47\n156\n84\n262\n160\n146\n82\n82\n211\n218\n249\n142\n82\n197\n257\n149\n137\n149\n307\n268\n265\n329\n391\n302\n747\n534\n398\n358\n302\n834\n865\n1117\n445\n695\n1378\n573\n359\n621\n300\n295\n1796\n482\n940\n505\n349\n434\n535\n379\n417\n927\n414\n599\n266\n522\n721\n366\n320\n534\n639\n739\n577\n484\n505\n429\n565\n473\n345\n398\n1082\n763\n284\n525\n632\n298\n431\n540\n401\n335\n506\n278\n300\n269\n477\n323\n704\n532\n291\n499\n388\n308\n269\n962\n461\n334\n360\n2232\n388\n475\n288\n279\n443\n324\n611\n370\n596\n258\n408\n343\n321\n769\n280\n257\n276\n673\n531\n1056\n532\n266\n266\n580\n368\n314\n342\n397\n349\n313\n474\n419\n276\n517\n277\n953\n273\n272\n275\n328\n498\n331\n321\n624\n290\n414\n413\n1299\n601\n881\n1669\n606\n322\n263\n360\n492\n299\n319\n355\n322\n544\n939\n713\n521\n414\n483\n142\n115\n88\n257\n248\n256\n132\n238\n164\n75\n252\n253\n138\n231\n28\n19\n138\n143\n148\n160\n243\n68\n255\n232\n142\n261\n82\n216\n227\n215\n174\n256\n138\n142\n228\n224\n159\n229\n258\n131\n254\n242\n37\n248\n249\n162\n104\n217\n247\n204\n253\n66\n126\n204\n191\n159\n218\n239\n237\n239\n237\n126\n99\n58\n255\n237\n255\n76\n27\n114\n238\n247\n160\n243\n37\n270\n160\n246\n251\n134\n256\n154\n60\n254\n88\n74\n138\n172\n87\n219\n254\n252\n131\n82\n229\n83\n69\n167\n193\n263\n176\n258\n258\n184\n162\n185\n98\n245\n248\n153\n89\n213\n245\n69\n87\n174\n110\n103\n257\n164\n108\n113\n72\n106\n76\n253\n246\n80\n83\n254\n42\n53\n256\n124\n211\n100\n259\n65\n251\n146\n144\n162\n69\n253\n100\n254\n135\n167\n199\n260\n187\n205\n244\n201\n153\n65\n88\n102\n120\n250\n151\n249\n252\n81\n257\n244\n84\n82\n186\n108\n213\n127\n85\n253\n231\n158\n145\n97\n83\n231\n214\n138\n262\n253\n216\n182\n195\n80\n148\n58\n43\n252\n66\n148\n97\n258\n66\n240\n103\n253\n219\n240\n245\n26\n253\n216\n160\n163\n258\n31\n106\n130\n135\n171\n101\n108\n146\n209\n237\n250\n54\n253\n103\n174\n209\n165\n248\n172\n108\n96\n162\n265\n232\n44\n209\n230\n165\n218\n115\n71\n68\n83\n107\n113\n186\n202\n90\n133\n117\n81\n246\n145\n46\n254\n255\n257\n247\n168\n194\n218\n246\n238\n250\n237\n154\n227\n205\n113\n75\n255\n251\n247\n160\n257\n117\n248\n245\n259\n91\n132\n223\n174\n260\n109\n131\n74\n148\n65\n181\n252\n252\n97\n74\n257\n85\n243\n44\n203\n193\n64\n54\n105\n232\n98\n33\n189\n167\n149\n232\n255\n103\n139\n217\n155\n235\n35\n253\n128\n204\n255\n72\n71\n211\n43\n258\n82\n123\n172\n209\n232\n109\n235\n57\n191\n139\n53\n96\n35\n210\n86\n161\n248\n255\n81\n76\n41\n251\n236\n218\n89\n176\n97\n186\n70\n101\n84\n248\n251\n262\n72\n94\n68\n83\n173\n41\n176\n46\n251\n256\n85\n182\n263\n61\n253\n205\n96\n120\n247\n89\n94\n174\n87\n122\n148\n256\n154\n178\n251\n138\n134\n140\n203\n264\n78\n191\n25\n250\n169\n56\n134\n189\n101\n267\n157\n100\n125\n230\n248\n179\n90\n24\n205\n253\n255\n234\n240\n250\n249\n162\n187\n130\n207\n247\n94\n200\n59\n239\n238\n248\n197\n69\n376\n240\n974\n1470\n211\n189\n111\n233\n324\n419\n"
    }
   ],
   "source": [
    "for item in data:\n",
    "    print(len(item[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open(\"dialog_data.txt\", \"w\")\n",
    "json_str = json.dumps(data)\n",
    "json.dump(json_str,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "('Hello doctor , I get a cough for the last few days , which is heavy during night times .  No contact with any Covid-19 persons . ',\n 'Hello , I understand your concern .  I just have a few more questions . ')"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "dictionary = {}\n",
    "MAX_LENGTH = 30\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from itertools import chain\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "punct = punctuation\n",
    "reverse_flag = False\n",
    "stopword_flag = False\n",
    "shorten_sentences_flag = True\n",
    "words_min_times = 0\n",
    "\n",
    "def shorten_sentences(str):\n",
    "    strs = str.split(\".\")\n",
    "    result = \"\"\n",
    "    length = 0\n",
    "    for i in range(len(strs)):\n",
    "        item = strs[i]\n",
    "        if len(item.split(\" \")) + length < MAX_LENGTH:\n",
    "            if i < len(strs) - 1:\n",
    "                result += item + \". \"\n",
    "            else:\n",
    "                result += item\n",
    "                return result\n",
    "            length = len(result.split(\" \"))\n",
    "    return result\n",
    "\n",
    "def clean_data(data):\n",
    "    for item in data:\n",
    "        for item2 in item:\n",
    "            words = word_tokenize(item2)\n",
    "            for word in words:\n",
    "                dictionary.setdefault(word,0)\n",
    "                dictionary[word] += 1\n",
    "    data2 = []\n",
    "    for item in data:\n",
    "        temp = []\n",
    "        flag = 0\n",
    "        if \"www\" in item[0] or \"www\" in item[1]:\n",
    "            continue\n",
    "        for item2 in item:\n",
    "            item2 = \" \".join([token for token in word_tokenize(item2) if dictionary[token] > words_min_times])\n",
    "            \n",
    "            if reverse_flag and flag == 1:\n",
    "                item2 = \" \".join(reversed(item2.split(\" \")))\n",
    "            if stopword_flag:\n",
    "                item2 = \" \".join([token for token in word_tokenize(item2) if token.lower() not in chain(punct, sw)])\n",
    "            if shorten_sentences_flag:\n",
    "                item2 = shorten_sentences(item2)\n",
    "            temp.append(item2)\n",
    "            flag += 1\n",
    "        temp = tuple(temp)\n",
    "        data2.append(temp)\n",
    "    return data2\n",
    "data2 = clean_data(data)\n",
    "data2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'sha sia ajss.  sdasds ss.  ds ssa aa a . '"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "shorten_sentences(\"sha sia ajss. sdasds ss. ds ssa aa a .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    #s = re.sub(r\"([.!?\\'])\", r\" \\1\", s)\n",
    "    #s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang):\n",
    "    print(\"Reading lines...\")\n",
    "    '''\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    '''\n",
    "    pairs = [(normalizeString(item[0]), normalizeString(item[1])) for item in data2]\n",
    "    # Reverse pairs, make Lang instances\n",
    "\n",
    "\n",
    "    lang = Lang(lang)\n",
    "\n",
    "    return lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Reading lines...\nRead 595 sentence pairs\nTrimmed to 595 sentence pairs\nCounting words...\nCounted words:\nlang 2846\n('hi .  .  i have been diagnosed with pnemonia and have not slept in 4 days because of the coughing .  .  .', \"hiafter spme days of the proper treatment you will feel better again .  do n't worry it takes ssometime to recover .  dr .  jolanda\")\n"
    }
   ],
   "source": [
    "def prepareData(lang):\n",
    "    lang, pairs = readLangs(lang)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        #print(pair)\n",
    "        lang.addSentence(pair[0])\n",
    "        lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(lang.name, lang.n_words)\n",
    "    return lang, pairs\n",
    "\n",
    "\n",
    "lang, pairs = prepareData('lang')\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    print(\"the size of data is:\", len(pairs))\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        p1 = pair[1].split(\" \")\n",
    "        if reverse_flag:\n",
    "            p1 = reseverd(p1)\n",
    "        print('=', \" \".join(p1))\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        if reverse_flag:\n",
    "            output_words = reseverd(output_words)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the size of data is: 20\n0m 24s (- 1m 39s) (200 20%) 4.0316\n0m 51s (- 1m 16s) (400 40%) 2.9769\n1m 16s (- 0m 51s) (600 60%) 2.1791\n1m 42s (- 0m 25s) (800 80%) 1.2945\n2m 11s (- 0m 0s) (1000 100%) 0.5993\n"
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, lang.n_words, dropout_p=0.1).to(device)\n",
    "pairs = pairs[:20]\n",
    "trainIters(encoder1, attn_decoder1, 1000, print_every=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "> thank you doctor , i really appreciate your help so much .  i appreciate your time and effort to help me and give advice .\n= hi , do not worry so much .  you will be absolutely alright .  give it some time .\n< hi , do not worry so much .  you will be absolutely alright .  give it some time . <EOS>\n\n> hello doctor , i get a cough for the last few days , which is heavy during night times .  no contact with any covid-19 persons .\n= hello , i understand your concern .  i just have a few more questions .\n< hello , i understand your concern .  i just have a few more questions . <EOS>\n\n> thank you doctor , as of now 12:40 pm i am breathing harder than usual since 30 minutes ago .  hours later was better .\n= hello , always protonix is better than zantac .  try using protonix ( pantoprazole ) .  do not lie down immediately after consuming meals .\n< hello , always protonix is better than zantac .  try using protonix ( pantoprazole ) .  do not lie down immediately after consuming meals . <EOS>\n\n> hi , i am chaitanya , 27 years old .  i use to swim daily in morning .\n= hello and welcome to ask a doctor service .  i have reviewed your query and here is my advice .  hope it helps .\n< hello and welcome to ask a doctor service .  i have reviewed your query and here is my advice .  hope it helps . <EOS>\n\n> thank you doctor , i have phlegm but not a lot .  a tiny amount comes out most of the time .\n= hi , i would recommend you take n-acetylcysteine 200 mg powder dissolved in water three times a day .\n< hi , i would recommend you take n-acetylcysteine 200 mg powder dissolved in water three times a day . <EOS>\n\n> thank you doctor , as of now 12:40 pm i am breathing harder than usual since 30 minutes ago .  hours later was better .\n= hello , always protonix is better than zantac .  try using protonix ( pantoprazole ) .  do not lie down immediately after consuming meals .\n< hello , always protonix is better than zantac .  try using protonix ( pantoprazole ) .  do not lie down immediately after consuming meals . <EOS>\n\n> thank you doctor , i have phlegm but not a lot .  a tiny amount comes out most of the time .\n= hi , i would recommend you take n-acetylcysteine 200 mg powder dissolved in water three times a day .\n< hi , i would recommend you take n-acetylcysteine 200 mg powder dissolved in water three times a day . <EOS>\n\n> hello doctor , last night i was getting chills , feeling more cold than usual and lightheaded and a lot of burping .\n= \n<  <EOS>\n\n> i have covid 19 symptoms ?\n= without any details it 's impossible to say .\n< without any details it 's impossible to say . <EOS>\n\n> what is the treatment for covid-19 ?\n= depends on severity .  covid-19 pandemic at this time , so a doctor on video may consult by video instead of requiring an in-person visit .\n< depends on severity .  covid-19 pandemic at this time , so a doctor on video may consult by video instead of requiring an in-person visit . <EOS>\n\n"
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('hello doctor , i get a cough for the last few days , which is heavy during night times .  no contact with any covid-19 persons .',\n  'hello , i understand your concern .  i just have a few more questions .'),\n ('thank you doctor , i have phlegm but not a lot .  a tiny amount comes out most of the time .',\n  'hi , i would recommend you take n-acetylcysteine 200 mg powder dissolved in water three times a day .'),\n ('hello doctor , i am suffering from coughing , throat infection from last week .  two days later , i consulted with a doctor .',\n  'hello , i can understand your concern .  in my opinion , you should get done a chest x-ray and cbc ( complete blood count ) .'),\n ('thank you doctor , after doing all these i can upload all for further query .',\n  'hi , yes , upload in this query only .  i will see and revert to you .'),\n ('thank you doctor , as per your guidelines , i have made one test .  fever is coming every 12 hours .  please advice .',\n  'hi , i can understand your concern .  i have gone through the report you have attached .  i hope this helps .'),\n ('should she start it ? and also can i start an iron tablet today itself ?',\n  'hi , yes , you can take iron tablet from today onwards .  and no need for azithromycin now as you have already taken it .'),\n ('hello doctor , i am a 23-year-old man .  i have anxiety and depression but no immunodeficiency disorders or chronic diseases .',\n  'hello .  anxiety can manifest itself in physical or psychological symptoms or both .  also please do not believe the hype about covid .'),\n ('hello doctor , last night i was getting chills , feeling more cold than usual and lightheaded and a lot of burping .',\n  ''),\n ('thank you doctor , i travel to school , nearby grocery stores in the bus .  no airport exposure .',\n  'hi , most probably with the history it does not appear like a severe problem or coronavirus infection .  drink plenty of water and warm fluids .'),\n ('so far , seems no one got any severe coughs or pain so far .  i only hear minor coughs the past week or so .',\n  'hi , you have got it right .  follow all the precautions .  you will be alright soon .'),\n ('thank you doctor , as of now 12:40 pm i am breathing harder than usual since 30 minutes ago .  hours later was better .',\n  'hello , always protonix is better than zantac .  try using protonix ( pantoprazole ) .  do not lie down immediately after consuming meals .'),\n ('he said to try ranitidine .  then i think now it did not cause my heart to beat super fast this time which was strange .',\n  'hi , you need to take pantoprazole or any other proton pump inhibitor .  avoid heavy meals .  it does not appear sinister .'),\n ('thank you doctor , i was trying to finish the bowl of food in one hour .',\n  'hi , do not worry about it .  drink plenty of water but not immediately after a meal .  eat well cooked meats .'),\n ('thank you doctor , i really appreciate your help so much .  i appreciate your time and effort to help me and give advice .',\n  'hi , do not worry so much .  you will be absolutely alright .  give it some time .'),\n (\"yeah if it does n't get better laryngoscopy would be perfect .  i do n't eat much junk food that much .  .  .\",\n  'i guess you are in the right track .  with regards to food diet and exercise .  restart doing your exercise .'),\n ('hi , i am chaitanya , 27 years old .  i use to swim daily in morning .',\n  'hello and welcome to ask a doctor service .  i have reviewed your query and here is my advice .  hope it helps .'),\n ('what is the treatment for covid-19 ?',\n  'depends on severity .  covid-19 pandemic at this time , so a doctor on video may consult by video instead of requiring an in-person visit .'),\n ('criteria for covid test ?', 'real vs .  textbook .'),\n ('i have covid 19 symptoms ?',\n  \"without any details it 's impossible to say .\"),\n ('do i have covid 19 ?', \"without any details it 's impossible to say .\")]"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{0: 'SOS',\n 1: 'EOS',\n 2: 'thank',\n 3: 'you',\n 4: 'doctor',\n 5: ',',\n 6: 'after',\n 7: 'doing',\n 8: 'all',\n 9: 'these',\n 10: 'i',\n 11: 'can',\n 12: 'upload',\n 13: 'for',\n 14: 'further',\n 15: 'query',\n 16: '.',\n 17: 'hi',\n 18: 'yes',\n 19: 'in',\n 20: 'this',\n 21: 'only',\n 22: 'will',\n 23: 'see',\n 24: 'and',\n 25: 'revert',\n 26: 'to',\n 27: 'have',\n 28: 'covid',\n 29: '19',\n 30: 'symptoms',\n 31: '?',\n 32: 'without',\n 33: 'any',\n 34: 'details',\n 35: 'it',\n 36: \"'s\",\n 37: 'impossible',\n 38: 'say',\n 39: 'do',\n 40: 'is',\n 41: 'vomiting',\n 42: 'diarrhea',\n 43: 'a',\n 44: 'symptom',\n 45: 'of',\n 46: 'covid-19',\n 47: 'nausea',\n 48: 'andor',\n 49: 'occur',\n 50: 'fairly',\n 51: 'frequently',\n 52: 'early',\n 53: 'the',\n 54: 'infection',\n 55: 'but',\n 56: 'are',\n 57: 'rarely',\n 58: 'if',\n 59: 'ever',\n 60: 'cough',\n 61: 'fever',\n 62: \"n't\",\n 63: 'develop',\n 64: 'within',\n 65: 'day',\n 66: 'or',\n 67: 'two',\n 68: 'probably',\n 69: 'coronavirus',\n 70: '229e',\n 71: 'same',\n 72: 'as',\n 73: 'cov229e',\n 74: 'one',\n 75: 'several',\n 76: 'coronaviruses',\n 77: 'that',\n 78: 'cause',\n 79: 'common',\n 80: 'colds',\n 81: 'biologically',\n 82: 'related',\n 83: 'sars-cov-2',\n 84: '(',\n 85: ')',\n 86: 'different',\n 87: 'viruses',\n 88: 'where',\n 89: 'be',\n 90: 'tested',\n 91: 'your',\n 92: 'local',\n 93: 'health',\n 94: 'department',\n 95: 'we',\n 96: 'no',\n 97: 'idea',\n 98: 'here',\n 99: 'what',\n 100: 'set',\n 101: 'up',\n 102: 'live',\n 103: 'am',\n 104: 'at',\n 105: 'risk',\n 106: 'united',\n 107: 'states',\n 108: 'infections',\n 109: 'likely',\n 110: 'pick',\n 111: 'over',\n 112: 'next',\n 113: 'few',\n 114: 'weeks',\n 115: 'us',\n 116: 'avoiding',\n 117: 'travel',\n 118: 'following',\n 119: 'hand',\n 120: 'washing',\n 121: 'recommendations',\n 122: 'most',\n 123: 'important',\n 124: 'prophylactic',\n 125: 'measures',\n 126: 'true',\n 127: 'false',\n 128: 'anyone',\n 129: 'infected',\n 130: 'with',\n 131: 'start',\n 132: 'increases',\n 133: 'chances',\n 134: 'death',\n 135: 'compared',\n 136: 'person',\n 137: 'who',\n 138: 'just',\n 139: 'respiratory',\n 140: 'why',\n 141: 'brief',\n 142: ':',\n 143: 'datafrom',\n 144: 'data',\n 145: 'from',\n 146: 'china',\n 147: 'there',\n 148: 'has',\n 149: 'been',\n 150: 'association',\n 151: 'between',\n 152: 'worse',\n 153: 'seems',\n 154: 'inflammatory',\n 155: 'response',\n 156: 'associated',\n 157: 'people',\n 158: 'should',\n 159: 'shave',\n 160: 'my',\n 161: 'beard',\n 162: 'reduce',\n 163: 'contracting',\n 164: 'yesthis',\n 165: 'virus',\n 166: 'clings',\n 167: 'everything',\n 168: 'especially',\n 169: 'hairs',\n 170: 'either',\n 171: 'wash',\n 172: 'times',\n 173: 'spray',\n 174: 'alcohol',\n 175: 'off',\n 176: 'mild',\n 177: 'intermittent',\n 178: 'asthma',\n 179: 'an',\n 180: 'elevated',\n 181: 'group',\n 182: 'complications',\n 183: 'so',\n 184: 'continue',\n 185: 'use',\n 186: 'inhalers',\n 187: 'when',\n 188: 'occasionally',\n 189: 'necessary',\n 190: 'steroids',\n 191: 'them',\n 192: 'put',\n 193: 'me',\n 194: 'more',\n 195: 'maybebeing',\n 196: '50',\n 197: 'medical',\n 198: 'condition',\n 199: 'like',\n 200: 'makes',\n 201: 'higher',\n 202: 'illness',\n 203: 'including',\n 204: 'covid19',\n 205: 'appears',\n 206: 'less',\n 207: 'issue',\n 208: 'children',\n 209: 'youth',\n 210: 'would',\n 211: 'make',\n 212: 'think',\n 213: 'not',\n 214: 'bad',\n 215: 'cold',\n 216: 'got',\n 217: 'twice',\n 218: 'does',\n 219: 'mean',\n 220: 'nodiarrhea',\n 221: 'rule',\n 222: 'out',\n 223: 'traveled',\n 224: 'endemic',\n 225: 'areas',\n 226: 'met',\n 227: 'test',\n 228: 'possible',\n 229: 'taking',\n 230: 'extra',\n 231: 'vitamin',\n 232: 'c',\n 233: 'every',\n 234: 'help',\n 235: 'prevent',\n 236: 'catching',\n 237: 'flu',\n 238: 'how',\n 239: 'much',\n 240: 'recommended',\n 241: 'cwhile',\n 242: 'getting',\n 243: 'enough',\n 244: 'diet',\n 245: 'highly',\n 246: 'special',\n 247: 'ability',\n 248: 'best',\n 249: 'preventative',\n 250: 'frequent',\n 251: 'handwashing',\n 252: 'sneezingcoughingcold',\n 253: 'fevers',\n 254: 'steps',\n 255: 'self-care',\n 256: 'staying',\n 257: 'hydrated',\n 258: 'sleep',\n 259: 'yesit',\n 260: 'helps',\n 261: 'keep',\n 262: 'body',\n 263: 'good',\n 264: 'shape',\n 265: 'nutrition',\n 266: 'avoid',\n 267: 'by',\n 268: 'plane',\n 269: 'public',\n 270: 'transportation',\n 271: 'wear',\n 272: 'mask',\n 273: 'social',\n 274: 'distance',\n 275: 'try',\n 276: 'touch',\n 277: 'surfaces',\n 278: 'hands',\n 279: 'clean',\n 280: 'still',\n 281: 'video',\n 282: 'text',\n 283: 'chat',\n 284: 'allegra',\n 285: 'increased',\n 286: 'viral',\n 287: 'dangerous',\n 288: 'take',\n 289: 'during',\n 290: 'pandemic',\n 291: 'being',\n 292: 'cautious',\n 293: 'medication',\n 294: 'increase',\n 295: 'potential',\n 296: 'avoided',\n 297: 'outbreak',\n 298: 'such',\n 299: 'seeing',\n 300: 'now',\n 301: 'contact',\n 302: 'positive',\n 303: 'last',\n 304: '12-day',\n 305: 'asymptomatic',\n 306: 'confirm',\n 307: 'contracted',\n 308: 'don',\n 309: 'â€™',\n 310: 't',\n 311: 'responsible',\n 312: 'wait',\n 313: 'till',\n 314: 'manifest',\n 315: 'isolate',\n 316: 'really',\n 317: 'need',\n 318: 'testing',\n 319: 'act',\n 320: 'contagious',\n 321: '14',\n 322: 'days',\n 323: 'consult',\n 324: 'gp',\n 325: 'get',\n 326: 'unknown',\n 327: 'sore',\n 328: 'throat',\n 329: 'slight',\n 330: 'well',\n 331: 'slightly',\n 332: 'dry',\n 333: 'eyes',\n 334: 'may',\n 335: 'individuals',\n 336: 'unknowingly',\n 337: 'detail',\n 338: 'temperature',\n 339: 'internationally',\n 340: 'locally',\n 341: 'seeming',\n 342: 'becoming',\n 343: 'vigilant',\n 344: 'about',\n 345: 'suggest',\n 346: 'appointment',\n 347: 'morning',\n 348: '2',\n 349: 'woke',\n 350: 'was',\n 351: 'lot',\n 352: 'better',\n 353: 'little',\n 354: 'scratchy',\n 355: 'other',\n 356: 'were',\n 357: 'stuffy',\n 358: 'nose',\n 359: 'bit',\n 360: 'on',\n 361: 'side',\n 362: 'corona',\n 363: 'sounds',\n 364: 'seasonal',\n 365: 'allergy',\n 366: 'gargle',\n 367: 'warm',\n 368: 'salt',\n 369: 'water',\n 370: 'meds',\n 371: 'home',\n 372: 'ask',\n 373: 'questions',\n 374: 'forum',\n 375: '-',\n 376: 'go',\n 377: 'unless',\n 378: 'pneumonia',\n 379: 'vaccines',\n 380: 'prevnar',\n 381: 'pneumovax',\n 382: 'developing',\n 383: 'catch',\n 384: 'bacterial',\n 385: 'they',\n 386: 'effect',\n 387: 'termometer',\n 388: 'cheek',\n 389: 'persistent',\n 390: 'comes',\n 391: 'goes',\n 392: 'feel',\n 393: 'hot',\n 394: 'nasal',\n 395: 'parangities',\n 396: 'long',\n 397: 'time',\n 398: 'years',\n 399: 'come',\n 400: 'while',\n 401: 'sound',\n 402: 'treat',\n 403: 'pharmacist',\n 404: 'assist',\n 405: 'phone',\n 406: 'collect',\n 407: 'irbesartan',\n 408: 'angiotensin',\n 409: 'receptor',\n 410: 'blocker',\n 411: 'uncomplicated',\n 412: 'hypertension',\n 413: 'cell',\n 414: 'expression',\n 415: 'receptors',\n 416: 'ar',\n 417: 's',\n 418: 'enters',\n 419: 'cells',\n 420: 'via',\n 421: 'change',\n 422: 'blood',\n 423: 'pressure',\n 424: 'thanks',\n 425: 'dr',\n 426: 'rather',\n 427: 'hold',\n 428: 'regular',\n 429: 'discuss',\n 430: 'telephone',\n 431: 'regarding',\n 432: 'stop',\n 433: 'own',\n 434: 'state',\n 435: 'officials',\n 436: 'temp',\n 437: 'ban',\n 438: 'activities',\n 439: '&',\n 440: 'shut',\n 441: 'down',\n 442: 'nonessential',\n 443: 'businesses',\n 444: 'curb',\n 445: 'spread',\n 446: 'light',\n 447: 'hosting',\n 448: 'yoga',\n 449: 'class',\n 450: 'school',\n 451: 'parking',\n 452: 'unwise',\n 453: 'neighbor',\n 454: \"'m\",\n 455: 'concerned',\n 456: 'delayvirtual',\n 457: 'virtual',\n 458: 'togethers',\n 459: 'considered',\n 460: 'least',\n 461: '6',\n 462: 'feet',\n 463: 'persons',\n 464: 'household',\n 465: 'ritonavir',\n 466: '100mg',\n 467: 'lopinavir400mg',\n 468: 'safe',\n 469: 'drugs',\n 470: 'improvement',\n 471: 'appear',\n 472: 'patient',\n 473: 'support',\n 474: 'clinical',\n 475: 'trials',\n 476: 'needed',\n 477: '10',\n 478: 'month',\n 479: 'old',\n 480: 'son',\n 481: 'his',\n 482: 'measles',\n 483: 'vaccinations',\n 484: 'due',\n 485: 'until',\n 486: 'calmed',\n 487: 'dont',\n 488: 'want',\n 489: 'expose',\n 490: 'him',\n 491: 'unnecessarily',\n 492: 'clinics',\n 493: 'hospitals',\n 494: 'talking',\n 495: 'platform',\n 496: 'stay',\n 497: 'baby',\n 498: 'boy',\n 499: 'scheduled',\n 500: 'vaccination',\n 501: 'lockdown',\n 502: 'know',\n 503: 'exposing',\n 504: 'advice',\n 505: 'exposure',\n 506: 'right',\n 507: 'quarantine',\n 508: 'against',\n 509: 'run',\n 510: 'sanitizer',\n 511: 'soap',\n 512: 'providing',\n 513: 'available',\n 514: 'easily',\n 515: 'trying',\n 516: 'shared',\n 517: 'places',\n 518: 'also',\n 519: 'protect',\n 520: 'some',\n 521: 'extent',\n 522: 'wife',\n 523: 'found',\n 524: 'she',\n 525: 'sat',\n 526: 'someone',\n 527: 'tuesday',\n 528: 'please',\n 529: 'advise',\n 530: 'reporting',\n 531: 'coming',\n 532: 'soon',\n 533: 'easy',\n 534: 'everyone',\n 535: 'year',\n 536: 'small',\n 537: 'worried',\n 538: 'her',\n 539: 'traveler',\n 540: 'area',\n 541: '>',\n 542: '100',\n 543: '4f',\n 544: 'than',\n 545: 'close',\n 546: 'quarters',\n 547: 'recently',\n 548: 'europe',\n 549: 'away',\n 550: 'order',\n 551: 'lower',\n 552: 'absolutely',\n 553: 'morningwithout',\n 554: 'rude',\n 555: 'quite',\n 556: 'stringent',\n 557: 'sanitizing',\n 558: 'face',\n 559: 'monitor',\n 560: 'sure',\n 561: '!',\n 562: 'leave',\n 563: 'product',\n 564: 'fridge',\n 565: 'die',\n 566: 'survive',\n 567: 'frozen',\n 568: 'food',\n 569: 'shows',\n 570: 'transfer',\n 571: 'sources',\n 572: 'way',\n 573: 'low',\n 574: 'high',\n 575: 'temperatures',\n 576: 'which',\n 577: 'fragile',\n 578: 'might',\n 579: 'hope',\n 580: '-80',\n 581: 'kill',\n 582: '+56',\n 583: 'hear',\n 584: 'dies',\n 585: 'around',\n 586: '27c',\n 587: 'once',\n 588: 'outside',\n 589: 'rises',\n 590: 'above',\n 591: '27',\n 592: 'dead',\n 593: 'disprin',\n 594: 'compral',\n 595: 'pils',\n 596: 'contain',\n 597: 'ibuprophen',\n 598: 'depends',\n 599: 'treatment',\n 600: 'far',\n 601: 'symptomatic',\n 602: 'supportive',\n 603: 'disprincompral',\n 604: 'ibuprofen',\n 605: 'm',\n 606: 'sick',\n 607: 'because',\n 608: 'diabetes',\n 609: 'anything',\n 610: 'anxiety',\n 611: 'care',\n 612: '1',\n 613: 'hands2',\n 614: 'can3',\n 615: 'control',\n 616: 'glucose',\n 617: 'levels4',\n 618: 'meditate',\n 619: 'search',\n 620: 'breathing',\n 621: 'exercises',\n 622: 'ago',\n 623: 'started',\n 624: 'experiencing',\n 625: 'fatigue',\n 626: 'random',\n 627: 'pains',\n 628: 'mostly',\n 629: 'below',\n 630: 'ribs',\n 631: 'sweating',\n 632: 'feeling',\n 633: 'give',\n 634: 'flue',\n 635: 'insist',\n 636: 'shouldnt',\n 637: 'history',\n 638: 'international',\n 639: 'virsu',\n 640: 'night',\n 641: '23rd',\n 642: 'march',\n 643: 'soar',\n 644: 'block',\n 645: 'visited',\n 646: 'yesterday',\n 647: 'given',\n 648: 'advised',\n 649: 'since',\n 650: 'normal',\n 651: 'concern',\n 652: 'ashmatic',\n 653: 'using',\n 654: 'chest',\n 655: 'tight',\n 656: 'throught',\n 657: 'lungs',\n 658: 'yet',\n 659: 'respiration',\n 660: 'rate',\n 661: 'google',\n 662: 'per',\n 663: 'minute',\n 664: '25',\n 665: 'battling',\n 666: 'breath',\n 667: 'hey',\n 668: 'had',\n 669: '``',\n 670: \"''\",\n 671: 'week',\n 672: 'grade',\n 673: 'past',\n 674: 'dizzy',\n 675: 'dizziness',\n 676: 'he',\n 677: 'reasons',\n 678: 'headache',\n 679: 'availability',\n 680: 'telephonic',\n 681: 'capability',\n 682: 'stretched',\n 683: 'self',\n 684: 'currently',\n 685: 'semi',\n 686: 'emerging',\n 687: 'wisdom',\n 688: 'tooth',\n 689: 'sharp',\n 690: 'growing',\n 691: 'inner',\n 692: 'causing',\n 693: 'discomfort',\n 694: 'ease',\n 695: 'ca',\n 696: 'surgery',\n 697: 'remove',\n 698: 'nsaids',\n 699: 'otc',\n 700: 'pain',\n 701: 'inflammation',\n 702: 'calling',\n 703: 'oral',\n 704: 'surgeon',\n 705: 'offices',\n 706: 'open',\n 707: 'emergencies',\n 708: 'falls',\n 709: 'into',\n 710: 'category',\n 711: '3',\n 712: 'call',\n 713: 'pharmacy',\n 714: 'article',\n 715: '2017',\n 716: 'singulair',\n 717: 'could',\n 718: 'influenza',\n 719: 'alveolar',\n 720: 'deep',\n 721: 'lrt',\n 722: 'god',\n 723: 'bless',\n 724: 'new',\n 725: 'based',\n 726: 'paper',\n 727: 'https',\n 728: 'journals',\n 729: 'plos',\n 730: 'orgplospathogensarticle',\n 731: 'through',\n 732: 'isolation',\n 733: 'very',\n 734: 'urgent',\n 735: 'steroid',\n 736: 'tab',\n 737: 'rinses',\n 738: 'allergic',\n 739: 'saline',\n 740: 'antihistamine',\n 741: 'often',\n 742: 'helpful',\n 743: 'controlling',\n 744: 'report',\n 745: 'shortness',\n 746: 'pcp',\n 747: 'having',\n 748: 'course',\n 749: 'today',\n 750: 'coughing',\n 751: 'first',\n 752: 'telephonically',\n 753: 'access',\n 754: 'panado',\n 755: 'fluids',\n 756: 'rest',\n 757: 'reoccurring',\n 758: 'strep',\n 759: 'throattonsillitis',\n 760: 'problems',\n 761: 'vulnerable',\n 762: 'apparently',\n 763: 'needs',\n 764: 'mucosa',\n 765: 'lips',\n 766: 'mouth',\n 767: 'infect',\n 768: 'follow',\n 769: 'authorities',\n 770: 'wet',\n 771: 'sometimes',\n 772: 'took',\n 773: 'starting',\n 774: 'painful',\n 775: 'sneezed',\n 776: 'hour',\n 777: 'general',\n 778: 'physician',\n 779: 'direct',\n 780: 'proper',\n 781: 'book',\n 782: 'consultation',\n 783: 'office',\n 784: 'instructions',\n 785: 'specific',\n 786: 'animals',\n 787: 'pets',\n 788: 'others',\n 789: 'limited',\n 790: 'reading',\n 791: 'infests',\n 792: 'varieties',\n 793: 'bats',\n 794: 'snakes',\n 795: 'dog',\n 796: 'cat',\n 797: 'list',\n 798: 'tired',\n 799: 'hard',\n 800: 'buy',\n 801: 'free',\n 802: 'post',\n 803: 'again',\n 804: 'its',\n 805: 'feels',\n 806: 'something',\n 807: 'stuck',\n 808: 'putting',\n 809: 'info',\n 810: 'travelled',\n 811: 'ibuprufen',\n 812: 'thisbseasonnof',\n 813: 'paracetamol',\n 814: 'medications',\n 815: 'unaware',\n 816: 'contraindications',\n 817: 'both',\n 818: 'taken',\n 819: '4',\n 820: 'hours',\n 821: 'sms',\n 822: 'stating',\n 823: 'ibuprofin',\n 824: 'advil',\n 825: 'mypaid',\n 826: 'myprodol',\n 827: 'fewer',\n 828: 'increasing',\n 829: 'multiplication',\n 830: 'look',\n 831: 'unprecedented',\n 832: 'convey',\n 833: 'switch',\n 834: 'napacod',\n 835: 'hashimotos',\n 836: 'nodules',\n 837: 'checked',\n 838: 'yearly',\n 839: 'thyroid',\n 840: 'specialist',\n 841: 'preschool',\n 842: 'teacher',\n 843: 'assistant',\n 844: 'work',\n 845: '47',\n 846: 'yr',\n 847: 'female',\n 848: 'level',\n 849: 'nearly',\n 850: 'assuming',\n 851: 'immunosuppresive',\n 852: 'therapy',\n 853: 'distancing',\n 854: 'exposed',\n 855: 'quit',\n 856: 'smoking',\n 857: 'non',\n 858: 'smoke',\n 859: 'vape',\n 860: 'lung',\n 861: 'scarring',\n 862: 'thought',\n 863: 'heard',\n 864: 'changes',\n 865: 'structure',\n 866: 'microscopically',\n 867: 'seen',\n 868: 'x-rays',\n 869: 'air',\n 870: 'beyond',\n 871: 'airborne',\n 872: 'facts',\n 873: 'primarily',\n 874: 'acquired',\n 875: 'number',\n 876: 'potentially',\n 877: 'dissipate',\n 878: 'allergies',\n 879: 'else',\n 880: 'many',\n 881: 'online',\n 882: 'resources',\n 883: 'distinguish',\n 884: 'told',\n 885: 'otherwise',\n 886: 'daughter',\n 887: 'drip',\n 888: 'amoxicillin',\n 889: 'panamol',\n 890: 'rhineton',\n 891: 'ear',\n 892: 'diagnosed',\n 893: 'monday',\n 894: 'back',\n 895: 'cape',\n 896: 'town',\n 897: 'plenty',\n 898: 'trouble',\n 899: 't=breathing',\n 900: 'itchyburning',\n 901: 'n',\n 902: 'b',\n 903: 'antibacterial',\n 904: 'handsoap',\n 905: 'specialized',\n 906: 'rid',\n 907: 'germs',\n 908: 'im',\n 909: 'confused',\n 910: 'read',\n 911: 'internet',\n 912: 'kind',\n 913: 'doesnt',\n 914: 'matter',\n 915: 'effective',\n 916: 'advertise',\n 917: 'claim',\n 918: 'swelling',\n 919: 'accompanied',\n 920: 'warmth',\n 921: 'red',\n 922: 'patch',\n 923: 'elbow',\n 924: 'aches',\n 925: 'problem',\n 926: 'requiring',\n 927: 'seek',\n 928: 'evaluation',\n 929: 'preferably',\n 930: 'consultations',\n 931: 'healthtap',\n 932: ';',\n 933: 'click',\n 934: 'talk-to-doctor',\n 935: 'athraway',\n 936: 'chronic',\n 937: 'rheumatoid',\n 938: 'arthritis',\n 939: 'complicate',\n 940: 'things',\n 941: 'relating',\n 942: 'huge',\n 943: 'nurse',\n 944: 'scared',\n 945: 'end',\n 946: 'hopefully',\n 947: 'protocol',\n 948: 'handle',\n 949: 'institution',\n 950: 'ppe',\n 951: 'personal',\n 952: 'protective',\n 953: 'equipment',\n 954: 'properly',\n 955: 'mixed',\n 956: 'name',\n 957: 'family',\n 958: 'each',\n 959: 'disease',\n 960: 'linked',\n 961: 'present',\n 962: 'mixture',\n 963: 'isolating',\n 964: 'severe',\n 965: 'immunity',\n 966: 'mental',\n 967: 'strong',\n 968: 'point',\n 969: 'developed',\n 970: 'drink',\n 971: 'lots',\n 972: 'liquids',\n 973: 'tylenol',\n 974: 'severely',\n 975: 'joint',\n 976: 'did',\n 977: 'uncomfortable',\n 978: 'position',\n 979: 'neck',\n 980: 'shoulder',\n 981: 'wrist',\n 982: 'must',\n 983: 'alone',\n 984: 'indication',\n 985: 'prolia',\n 986: 'injection',\n 987: 'beginning',\n 988: 'april',\n 989: 'safer',\n 990: 'postpone',\n 991: 'situation',\n 992: 'definitely',\n 993: '2-4',\n 994: 'practice',\n 995: 'although',\n 996: 'gloves',\n 997: 'etc',\n 998: 'n95',\n 999: 'gown',\n ...}"
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "lang.index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "5391"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "lang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('thank you doctor , after doing all these i can upload all for further query .',\n  '. you to revert and see will i . only query this in upload , yes , hi'),\n ('i have covid 19 symptoms ?',\n  \". say to impossible 's it details any without\"),\n ('do i have covid 19 ?', \". say to impossible 's it details any without\"),\n ('is the coronavirus 229e the same as covid-19 ?',\n  '. viruses different but , ) covid-19 of cause the ( sars-cov-2 to related biologically . colds common cause that coronaviruses several of one is cov229e'),\n ('where can i be tested for covid 19 ?',\n  '. live you where is up set your what here idea no have we , department health local , doctor local your'),\n ('am i at risk for covid-19 in the united states ?',\n  '. measures prophylactic important most the probably are recommendations washing hand following and travel avoiding . us in weeks few next the over up pick likely will infections covid'),\n ('should i shave my beard to reduce my chances of contracting coronavirus / covid-19 ?',\n  '. off shave or alcohol with spray and day a times few a beard your wash either . hairs especially everything to clings virus this yes : brief in'),\n ('can taking extra steps for self-care ( like staying hydrated , getting more sleep ) every day help prevent you from catching the coronavirus or the flu ?',\n  '. nutrition good and shape good in body the keep to helps it yes : brief in'),\n ('do i have covid 19 ?',\n  \"? me with chat text or video to like you would . say to impossible 's it details any without unknown : brief in\"),\n ('will getting either of the pneumonia vaccines , prevnar and pneumovax , prevent you from developing pneumonia if you catch the flu or covid ?',\n  '. pneumonia viral on effect no have they . pneumonia bacterial prevent vaccines the . no'),\n ('how do i know if i have corona virus ?', '! tested get , sure be to'),\n ('if i leave covid 19 infected product in fridge , will virus die or survive in the fridge ?',\n  '. . way this sources food via virus of transfer no is there that shows food frozen from data . covid'),\n ('i hear covid 19 virus dies around 27c . does it mean once temperature outside rises above 27 c all covid 19 viruses outside will be dead ?',\n  '. it kill does c +56 it kill not does c -80 . hope might one as . fragile as not'),\n ('if i have had a sore throat for 3 days but with no fever should i be tested for covid-19 ?',\n  'call'),\n ('how do i book a virtual consultation with my doctor for covid-19 ?',\n  \"? me with chat text or video to like you would instructions for office 's doctor your call doctor your call : brief in\"),\n ('i also have a dry throat sometimes its feels like there is something stuck or putting pressure on my throat ?',\n  '? patient virus corona a with contact into come or travelled you have . info more need'),\n ('i have a 2 years old with cough n fever sweating which is worse at night , can she b tested for covid19 ?',\n  '? me with chat text or video to like you would . advise for doctor your call yes : brief in'),\n ('i use athraway chronic for rheumatoid arthritis , will this complicate things relating to the corona virus ?',\n  '. virus corona on effect any have will it think not do i . no'),\n ('i have a prolia injection appointment at the beginning of april . will it be safer to postpone the appointment because of the covid-19 situation ? prolia appointment',\n  '. . least at weeks 2-4 by treatment the postpone can you definitely . yes . postpone yes'),\n ('hi , can i use oralcon birth control pills even though we have the coronavirus epademic ?',\n  '? me with chat text or video to like you would . virus the and bcp using to contraindication any of unaware am i yes : brief in'),\n ('is it safe to eat food prepared by someone with coronavirus ? even if they wear a mask and gloves ?',\n  '. food prepare to enough protectve not is gear protective the . skip to better'),\n ('can the meat i eat give me coronavirus ? will cooking kill the coronavirus ?',\n  '. microwave , of sec virus-30 the kill will adequately cooking . kill will cooking'),\n ('does a virus cause lesions dry and oily nose',\n  '? me with chat text or video to like you would discharge moist increase nose runny cause to likely more not usually : brief in'),\n ('i am the main member of discovery , i want to complete a health covid assessment for my husband ? please let me know how to do so ?',\n  \"? me with chat text or video to like you would . discovery call to need 'll you discovery call : brief in\"),\n ('body ache and fever , scratchy itchy throat ?',\n  '! through follow then hospitalization possible and self-quarantine , testing regarding instructions get to provider care health your call ? covid-19 early'),\n ('i think i need to be tested for covid-19 ?',\n  '. wil dr ? symptoms concern/ your is what . patient dear . 19 covid'),\n ('vomiting , diarrhea , achey , dizzy and weak fever has kept rising and is now at 103 . 4 any advice ?',\n  '. . physician a by ordered tests get , hydrated stay , tylenol take . coronavirus even or flu , gastroenteritis infectious an have you seem . infection'),\n ('i travelled to mauritius and do not have symptoms . should i get tested for covid19 ?',\n  '. platform this use or physician care primary your contact , symptomatic if . days 14 for quarantine self suggest . quarantine self')]"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}